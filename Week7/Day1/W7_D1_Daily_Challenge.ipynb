{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Web Scraping:\n",
        "\n",
        "use this website : Github/topics\n",
        "Write a Python script using the requests library to fetch the HTML content of the chosen website.\n",
        "Print the status code of the response to ensure the request was successful using .status_code, it should be 200.\n",
        "Print the first 100 characters of the HTML content to verify the response.\n",
        "Save the HTML content to a file named webpage.html. Ensure you handle the text encoding correctly.\n",
        "Use BeautifulSoup to parse the saved HTML content.\n",
        "Identify two distinct pieces of information on the webpage to extract (e.g., titles of the topics and their descriptions).\n",
        "Write code to extract these pieces of information. Ensure you identify the correct HTML tags and classes used for these elements on the webpage.\n",
        "Print the length and content of each extracted list to verify the extraction process.\n",
        "Create a Python dictionary to structure the extracted data, with keys representing the type of information (e.g., ‘title’ and ‘description’).\n",
        "Convert this dictionary into a pandas DataFrame.\n",
        "Print the DataFrame to confirm its structure and contents."
      ],
      "metadata": {
        "id": "H5j8-nyPQUuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFPCfi9gQM5H",
        "outputId": "d2a1e43f-11a3-4968-dedd-74bc5a8fc3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n",
            "Number of Titles: 30\n",
            "Number of Descriptions: 35\n",
            "Sample Titles: ['3D', 'Ajax', 'Algorithm', 'Amp', 'Android']\n",
            "Sample Descriptions: ['To see all available qualifiers, see our documentation.', 'Browse popular topics on GitHub.', 'A database is a structured set of data held in a computer, usually a server.', 'Maven is a build automation tool used primarily for Java projects.', 'JSON (JavaScript Object Notation) allows for easy interchange of data, often between a program and a database.']\n",
            "                     Title                                        Description\n",
            "0                       3D  To see all available qualifiers, see our docum...\n",
            "1                     Ajax                   Browse popular topics on GitHub.\n",
            "2                Algorithm  A database is a structured set of data held in...\n",
            "3                      Amp  Maven is a build automation tool used primaril...\n",
            "4                  Android  JSON (JavaScript Object Notation) allows for e...\n",
            "5                  Angular  3D refers to the use of three-dimensional grap...\n",
            "6                  Ansible  Ajax is a technique for creating interactive w...\n",
            "7                      API  Algorithms are self-contained sequences that c...\n",
            "8                  Arduino  Amp is a non-blocking concurrency library for ...\n",
            "9                  ASP.NET  Android is an operating system built by Google...\n",
            "10           Awesome Lists  Angular is an open source web application plat...\n",
            "11     Amazon Web Services  Ansible is a simple and powerful automation en...\n",
            "12                   Azure  An API (Application Programming Interface) is ...\n",
            "13                   Babel  Arduino is an open source platform for buildin...\n",
            "14                    Bash  ASP.NET is a web framework for building modern...\n",
            "15                 Bitcoin  An awesome list is a list of awesome things cu...\n",
            "16               Bootstrap  Amazon Web Services provides on-demand cloud c...\n",
            "17                     Bot  Azure is a cloud computing service created by ...\n",
            "18                       C  Babel is a compiler for writing next generatio...\n",
            "19                  Chrome  Bash is a shell and command language interpret...\n",
            "20        Chrome extension  Bitcoin is a cryptocurrency developed by Satos...\n",
            "21  Command-line interface  Bootstrap is an HTML, CSS, and JavaScript fram...\n",
            "22                 Clojure  A bot is an application that runs automated ta...\n",
            "23            Code quality  C is a general purpose programming language th...\n",
            "24             Code review  Chrome is a web browser from the tech company ...\n",
            "25                Compiler  Chrome extensions enable users to customize th...\n",
            "26  Continuous integration  A CLI, or command-line interface, is a console...\n",
            "27                     C++  Clojure is a dynamic, general-purpose programm...\n",
            "28          Cryptocurrency  Automate your code review with style, quality,...\n",
            "29                 Crystal  Ensure your code meets quality standards and s...\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Step 2: Fetch the webpage using requests\n",
        "url = 'https://github.com/topics'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "# Step 3: Print the status code to verify the request was successful\n",
        "print(\"Status Code:\", response.status_code)  # Should be 200 if successful\n",
        "\n",
        "# Step 4: Save the HTML content to a file named 'webpage.html'\n",
        "with open('webpage.html', 'w', encoding='utf-8') as file:\n",
        "    file.write(response.text)\n",
        "\n",
        "# Step 5: Parse the saved HTML content using BeautifulSoup\n",
        "# Re-open the saved HTML file to ensure the parsing is done from the saved file\n",
        "with open('webpage.html', 'r', encoding='utf-8') as file:\n",
        "    soup = BeautifulSoup(file, 'html.parser')\n",
        "\n",
        "# Step 6: Extract the topic titles from <p> tags with class 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
        "titles = [title.text.strip() for title in soup.find_all('p', class_='f3 lh-condensed mb-0 mt-1 Link--primary')]\n",
        "\n",
        "# Extract descriptions of topics from <p> tags with class 'color-fg-muted'\n",
        "descriptions = [desc.text.strip() for desc in soup.find_all('p', class_='color-fg-muted')]\n",
        "\n",
        "# Step 7: Print the length and content of each extracted list\n",
        "print(f\"Number of Titles: {len(titles)}\")\n",
        "print(f\"Number of Descriptions: {len(descriptions)}\")\n",
        "\n",
        "# Check the first few items of both lists\n",
        "print(\"Sample Titles:\", titles[:5])\n",
        "print(\"Sample Descriptions:\", descriptions[:5])\n",
        "\n",
        "# Step 8: Create a Python dictionary to store the extracted data\n",
        "min_length = min(len(titles), len(descriptions))  # Ensure both lists are the same length\n",
        "\n",
        "data = {\n",
        "    'Title': titles[:min_length],\n",
        "    'Description': descriptions[:min_length]\n",
        "}\n",
        "\n",
        "# Step 9: Convert the dictionary into a pandas DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 10: Print the DataFrame to confirm its structure and contents\n",
        "print(df)\n"
      ]
    }
  ]
}